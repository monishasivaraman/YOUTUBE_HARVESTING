# -*- coding: utf-8 -*-
"""YOUTUBE_HARVESTING.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17VHJgG5TWqMpcMOnzAprvdloOyS-SOC5
"""

# pip install google-api-python-client
# pip install pandas
# pip install pymango
# pip install --upgrade pymongo
# pip install mysql-connector-python

from googleapiclient.discovery import build
import pandas as pd
from googleapiclient.errors import HttpError
import pymango
from pymongo import MongoClient
import mysql.connector
from datetime import datetime

api_key = 'AIzaSyBTXXyE7lICykG7w5Xbf6NiBl-LO9ur4cU'#"AIzaSyDCQ-sXapHJo3A9BRQKepGpy4TRTxUtx7Q"
channel_id = ["UCCq1xDJMBRF61kiOgU90_kw",
              "UC2J_VKrAzOEJuQvFFtj3KUw",
              'UC2UXDak6o7rBm23k3Vv5dww',
              'UCiT9RITQ9PW6BhXK0y2jaeg']  

# I need to get the YT service based on the YT service i an raise a request and get the data
api_service_name = "youtube"
api_version = "v3"

youtube = build(api_service_name, api_version, developerKey=api_key)

# we have extract channel detials so that we gonna create function

# function to get channel detilas 
def get_channel_data(channel_id):
    all_data = []
    request = youtube.channels().list(
        part='snippet,contentDetails,statistics',
        id=','.join(channel_id))  #channel id is a sting so i cant pass list here so im converting list into string using join method )
    response = request.execute()

    for i in range(len(response['items'])):
        channel = response['items'][i]
        data = {
            'channel_id': channel_id[i],
            'channel_name': channel['snippet']['title'],
            'description': channel['snippet']['description'],
            'views': channel['statistics']["viewCount"],
            'subscriber': channel['statistics']["subscriberCount"],
            'total_video': channel['statistics']["videoCount"],
            'playlist_id':channel['contentDetails']['relatedPlaylists']['uploads']
        }
        all_data.append(data)

    return all_data

channel_statistics = get_channel_data(channel_id)
print(channel_statistics)
# converting into data frame 
channel_data= pd.DataFrame(channel_statistics)
channel_data

# function to get video_id
playlist_id ='UU2UXDak6o7rBm23k3Vv5dww'
def get_video_ids(playlist_id):
    request = youtube.playlistItems().list(
        part="contentDetails",
        playlistId=playlist_id,
         maxResults=50)
    response = request.execute()

    
    video_ids = [] # empty list is created to append the extracted value
    for item in response["items"]:
        video_id = item["contentDetails"]["videoId"]
        video_ids.append(video_id)


    while "nextPageToken" in response: # when there is nextpagetoken exists in the response  this condition gonna run
        request = youtube.playlistItems().list(
            part="contentDetails",
            playlistId=playlist_id,
            maxResults=50,
            pageToken=response["nextPageToken"]
        )
        response = request.execute()

        for item in response["items"]:
            video_id = item["contentDetails"]["videoId"]
            video_ids.append(video_id)

    return video_ids
video_ids=get_video_ids(playlist_id)
print(video_ids)

# function to get video_data
def get_video_data(video_ids):
  all_video_data=[]

  for i in range (0,len(video_ids),50): # the max value is 50 so we are using for loop to extract data 
      request = youtube.videos().list(
            part="snippet,contentDetails,statistics",
            id= ','.join(video_ids[i:i+50]))
      response = request.execute()

      for video in response['items']:
        video_stat= {'channel_id':video['snippet']['channelId'],
                     'title':video['snippet']['title'],
                      'published_date':video['snippet']['publishedAt'],
                      'views':video['statistics']['viewCount'],
                      'likes':video['statistics']['likeCount'],
                      'comment':video['statistics']['commentCount']}
        all_video_data.append(video_stat)            
  return all_video_data

video_data =get_video_data(video_ids) 
videos_data=pd.DataFrame(video_data)
videos_data

# function to get comment data
def get_video_comments(video_ids):
    all_comments = []
    for video_id in video_ids:
        try:
            comments_request = youtube.commentThreads().list(
                part="snippet",
                videoId=video_id,
                textFormat="plainText",
                maxResults=100
            )
            comments_response = comments_request.execute()

            while comments_response:
                for item in comments_response['items']:
                    comment_data = {'c':item['snippet']['videoId'],
                                    'comment': item["snippet"]["topLevelComment"]["snippet"]["textDisplay"]}
                    all_comments.append(comment_data)

                if 'nextPageToken' in comments_response:
                    page_token = comments_response['nextPageToken']
                    comments_response = youtube.commentThreads().list(
                        part="snippet",
                        videoId=video_id,
                        textFormat="plainText",
                        maxResults=100,
                        pageToken=page_token
                    ).execute()
                else:
                    break
        except HttpError as error:
             if error.resp.status == 403 and "commentsDisabled" in str(error): # if condition is running there to skip the error
               continue
            

    return all_comments
comments = get_video_comments(video_ids)
commend_data=pd.DataFrame(comments)
commend_data

#  to upload all the output data to mangobd atlas 

client = pymongo.MongoClient("mongodb+srv://jareshiahsamuel:Appasatti2.0@youtubeharvesting.a3rvgez.mongodb.net/?retryWrites=true&w=majority")
db = client["youtube_data"]
collection = db["TINA_DATA"]

# to insert channel data into collections
for data in channel_statistics:
  collection.insert_one(data)

# to insert video data into  Collections
for data in video_data:
  collection.insert_one(data)

# to insert comments into collection
for comment in comments: 
  collection.insert_one(comment)


# collection to retrieve the data
youtube_data = collection.find({})
for document in youtube_data:
    print(document)

# setting connection from python to mysql
mydb = mysql.connector.connect(
    host='localhost',
    user='root',
    password='J@reshiah2.0',
    database='youtube_harvesting'
)

cursor = mydb.cursor()

# to create channel table
channel_table = '''
    CREATE TABLE channel (
        channel_id VARCHAR(255) PRIMARY KEY,
        channel_name VARCHAR(255),
        description TEXT,
        views INT,
        subscriber INT,
        total_video INT,
        playlist_id VARCHAR(255)
    )
'''

cursor.execute(channel_table)

# insert data into the channel table
insert_query = '''
    INSERT INTO channel (channel_id, channel_name, description, views, subscriber, total_video, playlist_id)
    VALUES (%s, %s, %s, %s, %s, %s, %s)
'''
values = channel_data.values.tolist()
cursor.executemany(insert_query, values)
mydb.commit()

# Create video_data table
create_table = '''
    CREATE TABLE video_data(
        channel_id VARCHAR(225),
        title VARCHAR(255),
        published_date DATETIME,
        views INT,
        likes INT,
        comment INT
    )
'''
cursor.execute(create_table)

# changing the published_date values
videos_data['published_date'] = pd.to_datetime(videos_data['published_date'])
videos_data['published_date'] = videos_data['published_date'].dt.strftime('%Y-%m-%d %H:%M:%S')

# insert data into the video_data table
insert_query = '''
    INSERT INTO video_data (channel_id, title, published_date, views, likes, comment)
    VALUES (%s, %s, %s, %s, %s, %s)
'''
values = videos_data.values.tolist()
cursor.executemany(insert_query, values)
mydb.commit()

# To Create comments table
create_table = '''
    CREATE TABLE comments (
        video_id VARCHAR(255),
        comment TEXT
    )
'''
cursor.execute(create_table)

# insert data into the comments table
insert_query = '''
    INSERT INTO comments (video_id, comment)
    VALUES (%s, %s)
'''
values = commend_data[['video_id', 'comment']].values.tolist()
cursor.executemany(insert_query, values)
mydb.commit()

# Closing  the cursor and connection
cursor.close()
mydb.close()